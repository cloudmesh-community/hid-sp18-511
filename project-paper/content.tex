% status: 0
% chapter: TBD

\title{Automated Spark Cluster Deployment on EC2}


\author{Sandeep Khandelwal}
\affiliation{%
  \institution{Indiana University}
  \city{Bloomington} 
  \state{IN} 
  \postcode{47408}
  \country{USA}}
\email{skhande@iu.edu}


% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{Sandeep}


\begin{abstract}

This project is about developing a module for automated deployment of
Apache Spark cluster on AWS (Amazon Web Services) EC2 (Elastic Compute
Cloud) instances on a single click and perform various data related
tasks on Spark Cluster. This module will take care of different infrastructure
related items like provisioning of EC2 instance, setting up the
public/private key pair for secure connection with EC2 instance, inbound/outbound
traffic rules on provisioned machines to allow connectivity on various
ports. This module will also perform Apache Spark installation on the
provisioned EC2 instances using master/worker model. One of the
machine will work as a master node and other machines will work as
worker node. The script will expose options for Apache Spark cluster
deployment, execution of commands on Apache Spark cluster, and
termination of machines.

\end{abstract}

\keywords{AWS, EC2, Apache Spark, Apache Hadoop, Ansible}


\maketitle

\section{Introduction}

AWS~\cite{hid-sp18-511-www-aws} is a cloud service provider that
provides different types of on-demand services to the
customers. AWS~\cite{hid-sp18-511-www-aws} provides various services
to the customers in Infrastructure as a Service, Platform as a Service
and Software as a Service categories. EC2~\cite{hid-sp18-511-www-ec2}
is a compute service provided by AWS~\cite{hid-sp18-511-www-aws} for
easy and fast provisioning of compute resources of different type
based on the requirement. Apache Spark~\cite{hid-sp18-511-www-spark}
is an open source project which use in-memory data for fast and
optimized operation and use Apache
Hadoop~\cite{hid-sp18-511-www-hadoop} as underlying
framework. Ansible~\cite{hid-sp18-511-www-ansible} is an open source
automation platform for configuration management and application
deployment. Ansible~\cite{hid-sp18-511-www-ansible} automation tool will be used
in this project to provision EC2~\cite{hid-sp18-511-www-ec2} instances, deploy Apache Spark~\cite{hid-sp18-511-www-spark}
cluster on EC2~\cite{hid-sp18-511-www-ec2} instances and perform
various tasks on Apache Spark~\cite{hid-sp18-511-www-spark} cluster.

\section{Technology Used}
This section describes the technology used in the project.

\subsection{AWS}

AWS~\cite{hid-sp18-511-www-aws} is a secure cloud service provider
that provide various on-demand services.
AWS~\cite{hid-sp18-511-www-aws} provides service in Compute, Storage,
Database, Migration, Networking and Content Delivery, Developer Tools
and many more.

\paragraph{EC2}

EC2~\cite{hid-sp18-511-www-ec2} is AWS secure and resizable compute
service. EC2~\cite{hid-sp18-511-www-ec2} instances can be created on
demand with different configuration of memory, CPU power and hard
disk. EC2~\cite{hid-sp18-511-www-ec2} instances can be added and
terminated at run time based on the load of application. Adding or
terminating EC2{hid-sp18-511-www-ec2} instances is very easy and can
be done in few minutes.

\paragraph{Security Group}

Security Group define the inbound and outbound allowed traffic for
EC2~\cite{hid-sp18-511-www-ec2} instance.  We can define the allowed
incoming and outgoing traffic using Security Group and assign it to
the instance.  Security Group works as firewall and allow only
permitted traffic on EC2~\cite{hid-sp18-511-www-ec2} instance.

\paragraph{Key Pair}

Key Pair is used to connect to the EC2~\cite{hid-sp18-511-www-ec2}
instance. We need to create Key Pair and provide the private key to
connect to the EC2~\cite{hid-sp18-511-www-ec2} instance.

\subsection{Apache Spark}

Apache Spark~\cite{hid-sp18-511-www-spark} is analytics engine for
large scale data processing. Apache
Spark~\cite{hid-sp18-511-www-spark} has high performance engine, very
easy to use and provide option to plugin third party components.

\subsection{Ansible}

Ansible~\cite{hid-sp18-511-www-ansible} is open source software for
the infrastructure automation, configuration management and
application deployment.

\section{Deployment}

\subsection{Setup}

Create AWS account if not exist already and get the AWS ID and secret key.

Setup the git repository and provide the AWS ID and secret key before executing any command.

\begin{verbatim}
export HID=hid-sp18-511
mkdir -p ~/github/cloudmesh-community
cd ~/github/cloudmesh-community
git clone https://github.com/cloudmesh-community/$HID.git
\end{verbatim}

We need to provide the values for \verb|AWS_ACCESS_KEY_ID| and \verb|AWS_SECRET_ACCESS_KEY| before executing any command. Enter the information on command line 

\begin{verbatim}
export AWS_ACCESS_KEY_ID='<AWS_ACCESS_KEY_ID value>'
export AWS_SECRET_ACCESS_KEY='<AWS_SECRET_ACCESS_KEY value>'
\end{verbatim}

\subsection{Configuration options}

There are various configuration that can be updated based on the requirement.

AWS related configuration options -

\begin{verbatim}
cd ~/github/cloudmesh-community/$HID.git/project-code/group_vars/all
open main.yml file and update the following information
project_name: <specify the project name. Example - ec2_spark>
region: <specify AWS region. Example - us-west-2>
env: <deployment environment. Example - stg>
\end{verbatim}

EC2 related configuration options -

\begin{verbatim}
cd ~/github/cloudmesh-community/$HID.git/project-code/roles/provisionec2/defaults
open main.yml file and update the following information
ami_image: <EC2 AMI image type. Example - ami-4e79ed36>
instance_type: <Instance type. Example - t2.micro>
\end{verbatim}

\subsection{Deploy Apache Spark Cluster}

\TODO{Provide command and screen shots about Apache Spark Cluster deployment}

\subsection{Execute Command on Apache Spark Cluster}

\TODO{Provide command and screen shots about Command execution on Apache Spark Cluster}

\subsection{Terminate Apache Spark Cluster}

\TODO{Provide command and screen shots about Apache Spark Cluster termination}

\section{Results}
\TODO{Add results in the table. Specify the duration taken in the deployment and termination of the instances}

\begin{table}[hbt]
	\centering \caption{Results}\label{t:results-table} \begin{tabular}{llll} \end{tabular}
\end{table}


\section{Conclusion}

\TODO{Put here an conclusion. Conclusion and abstracts must not have any
	citations in the section.}


\begin{acks}

  The authors would like to thank Dr.~Gregor~von~Laszewski for his
  support and suggestions to write this paper.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 

