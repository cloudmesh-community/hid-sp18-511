% status: 80
% chapter: TBD

\title{Automated Spark Cluster Deployment on EC2}


\author{Sandeep Khandelwal}
\affiliation{%
  \institution{Indiana University}
  \city{Bloomington} 
  \state{IN} 
  \postcode{47408}
  \country{USA}}
\email{skhande@iu.edu}


% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{Sandeep}


\begin{abstract}

This project is about developing a module for automated deployment of
Apache Spark cluster on AWS (Amazon Web Services) EC2 (Elastic Compute
Cloud) instances on a single click and perform various data processing related
tasks on Spark Cluster. This project also does the benchmarking of 
deployment, data processing and termination of the instances.

\end{abstract}

\keywords{AWS, EC2, Apache Spark, Apache Hadoop, Ansible}


\maketitle

\section{Introduction}

This module does infrastructure related tasks of provisioning of
EC2~\cite{hid-sp18-511-www-ec2} instances, setting up the
public/private key pair for secure connection with EC2 instance,
inbound/outbound traffic rules on provisioned machines to allow
connectivity on various ports. This module also perform Apache Spark
installation on the provisioned EC2~\cite{hid-sp18-511-www-ec2}
instances using master/worker model and perform all required configuration. One of the machine will work as a
master node and other machines will work as worker node. The module
expose command line options for Apache
Spark~\cite{hid-sp18-511-www-spark} cluster deployment, execution of
commands on Apache Spark~\cite{hid-sp18-511-www-spark} cluster, and
termination of machines. Benchmarking is done for measuring the
deployment, data processing and termination of the instances.

Ansible~\cite{hid-sp18-511-www-ansible} automation tool is be used in
this project to provision EC2~\cite{hid-sp18-511-www-ec2} instances,
deploy Apache Spark~\cite{hid-sp18-511-www-spark} cluster on
EC2~\cite{hid-sp18-511-www-ec2} instance and perform various data
processing related tasks on Apache Spark~\cite{hid-sp18-511-www-spark}
cluster.

\section{Technologies Used}
This section describes the technology used in the project.

\begin{itemize}
	\item[$\bullet$] AWS
	\item[$\bullet$] Apache Spark
	\item[$\bullet$] Ansible
\end{itemize}

\section{AWS}

AWS~\cite{hid-sp18-511-www-aws} is a secure cloud service provider
that provide various on-demand services.
AWS~\cite{hid-sp18-511-www-aws} provides service in Compute, Storage,
Database, Migration, Networking and Content Delivery, Developer Tools
and many more. These services are easy to setup and can be done in few minutes. All the services are on demand service and AWS~\cite{hid-sp18-511-www-aws} charge only for the duration service being used. This is very effective and suitable for both small and large customers.

\subsection{EC2}

EC2~\cite{hid-sp18-511-www-ec2} is AWS secure and resizable compute
service. EC2~\cite{hid-sp18-511-www-ec2} instances can be created on
demand with different configuration of memory, CPU power and hard
disk. EC2~\cite{hid-sp18-511-www-ec2} instances can be added and
terminated at run time based on the load of application. Adding or
terminating EC2{hid-sp18-511-www-ec2} instances is very easy and can
be done in few minutes. 

Two EC2 instances are created in this project with following configuration. One 
of the instance is used for master and another one for worker node.

\begin{table}[]
	\centering \caption{Resource
	Specification} \label{t:resource-specification} \begin{tabular}{|l|l|l|l|l|l|} \hline \textbf{Instance}
	& \textbf{Image} & \textbf{Size} & \textbf{RAM}
	& \textbf{VCPUs} & \textbf{Disk} \\ \hline Node1 & Ubuntu
	Server 16.04(ami-4e79ed36) & t2.micro & 1GB & 1 &
	8GB \\ \hline Node2 & Ubuntu Server 16.04(ami-4e79ed36) &
	t2.micro & 1GB & 1 & 8GB \\ \hline \end{tabular}
\end{table}


\subsection{Security Group}

Security Group define the inbound and outbound allowed traffic for
EC2~\cite{hid-sp18-511-www-ec2} instance.  We can define the allowed
incoming and outgoing traffic using Security Group and assign it to
the instance.  Security Group works as firewall and allow only
permitted traffic on EC2~\cite{hid-sp18-511-www-ec2} instance.

\verb|ec2_spark_stg_security_group| Security group is created with the following
inbound and outbound ports open in this project and assigned to the EC2~\cite{hid-sp18-511-www-ec2} instances created

\begin{itemize}
	\item Inbound - 80, 8080, 22, 7178, 8181, 7077, 443
    \item Outbound - all
	
\end{itemize}

\subsection{Key Pair}

Key Pair is used to connect to EC2~\cite{hid-sp18-511-www-ec2}
instance. We need to create Key Pair and provide the private key to
connect to the EC2~\cite{hid-sp18-511-www-ec2} instance.

\verb|ec2_spark_stg_key| Key pair is created in this project.
The private key with the name \verb|ec2_spark_stg_key-private.pem| is
created on the user machine and used for making the ssh connection to
EC2~\cite{hid-sp18-511-www-ec2} instances.

\section{Apache Spark}

Apache Spark~\cite{hid-sp18-511-www-spark} is analytics engine for
large scale data processing. Apache
Spark~\cite{hid-sp18-511-www-spark} has high performance engine, very
easy to use and provide option to plugin third party components.

The following configuration is used in this project for Apache Spark

\begin{itemize}
	\item spark_version: 2.3.0
	\item spark_hadoop_version: 2.7
	\item spark_temp_dir: /tmp
	\item spark_working_dir: /var/lib/spark
	\item spark_install_dir: /opt/spark
	\item spark_mirror: http://apache.claz.org/spark/spark-2.3.0/
	\item spark_master_memory_mb: 1024
	\item spark_master_work_port: 7077
	\item spark_master_ui_port: 8080
	\item spark_worker_memory_mb: 1024
	\item spark_worker_work_port: 7178
	\item spark_worker_ui_port: 8181
\end{itemize}

\section{Ansible}

Ansible~\cite{hid-sp18-511-www-ansible} is open source software for
the infrastructure automation, configuration management and
application deployment. Automation tasks are defined in Ansible Playbook using YAML language. For
communication to hosts, Ansible~\cite{hid-sp18-511-www-ansible} uses OpenSSH.

For this project Ansible~\cite{hid-sp18-511-www-ansible} is used to create and setup EC2~\cite{hid-sp18-511-www-ec2} instances, deploy Apache Spark~\cite{hid-sp18-511-www-spark} cluster on EC2~\cite{hid-sp18-511-www-ec2} instance and perform various data processing related tasks on Apache Spark~\cite{hid-sp18-511-www-spark} Cluster.

\section{Deployment}

\subsection{Setup}

\paragraph{Ansible}
Download and install Ansible~\cite{hid-sp18-511-www-ansible} on the
machine where the deployment commands will be executed.

Ansible~\cite{hid-sp18-511-www-ansible} can be downloaded from 
\url{https://www.ansible.com/resources/get-started}

\paragraph{AWS key}

Create AWS account if not exist already and get the AWS ID and secret
key. These keys will be used in authentication with AWS.

We need to provide the values for \verb|AWS_ACCESS_KEY_ID|
and \verb|AWS_SECRET_ACCESS_KEY|. Enter the information on command line

\begin{verbatim}
export AWS_ACCESS_KEY_ID='<AWS_ACCESS_KEY_ID value>'
export AWS_SECRET_ACCESS_KEY='<AWS_SECRET_ACCESS_KEY value>'
\end{verbatim}

\paragraph{Git repository}

Setup the git repository.

\begin{verbatim}
export HID=hid-sp18-511
mkdir -p ~/github/cloudmesh-community
cd ~/github/cloudmesh-community
git clone https://github.com/cloudmesh-community/$HID.git
\end{verbatim}


\paragraph{Configuration options}

There are various configuration option that can be updated based on
the requirement.

AWS related configuration options -

\begin{verbatim}
cd ~/github/cloudmesh-community/$HID.git/project-code/group_vars/all
open main.yml file and update the following information as per the
requirement

project_name: <specify the project name. Example - ec2_spark>
region: <specify AWS region. Example - us-west-2>
env: <deployment environment. Example - stg>
\end{verbatim}

EC2 related configuration options -

\begin{verbatim}
cd
~/github/cloudmesh-community/$HID.git/project-code/roles
/provisionec2/defaults
open main.yml file and update the following information as per the
requirement
 
ami_image: <EC2 AMI image type. Example ami-4e79ed36>
instance_type: <Instance type. Example - t2.micro>
\end{verbatim}

\subsection{Deploy Apache Spark Cluster}

Execute the following command on the command line to Deploy the Apache
Spark Cluster.

\begin{verbatim}

\end{verbatim}

This command will be do the following things internally 

\begin{itemize}
	\item Create Security Group in AWS
	\item Create Key Pair in AWS
	\item Provision EC2 instance for Spark master
	\item Provision EC2 instance for Spark worker
	\item Create Spark user and group on Spark master
	\item Setup Spark specific directories on Spark master
	\item Download and unarchive Spark  on Spark master
	\item Download and install Java  on Spark master
	\item Setup Spark configuration files on Spark master
	\item Spark master service on Spark master
	\item Create Spark user and group on Spark worker
	\item Setup Spark specific directories on Spark worker
	\item Download and unarchive Spark  on Spark worker
	\item Download and install Java  on Spark worker
	\item Setup Spark configuration files on Spark worker
	\item Spark master service on Spark worker	
\end{itemize}

\TODO{Add screenshots and details. Also, setup for the worker}
\subsection{Execute Command on Apache Spark Cluster}

\TODO{Provide command and screen shots about Command execution on Apache Spark
Cluster}

\subsection{Terminate Apache Spark Cluster}

\TODO{Provide command and screen shots about Apache Spark Cluster termination}

\section{Results}
\TODO{Add results in the table. Specify the duration taken in the deployment
and termination of the instances}

\begin{table}[hbt]
	\centering \caption{Results}\label{t:results-table} \begin{tabular}{llll} \end{tabular}
\end{table}


\section{Conclusion}

\TODO{Put here an conclusion. Conclusion and abstracts must not have any
	citations in the section.}


\begin{acks}

  The authors would like to thank Dr.~Gregor~von~Laszewski for his
  support and suggestions to write this paper.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 

